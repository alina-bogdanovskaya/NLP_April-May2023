{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c27e2c",
   "metadata": {
    "cellId": "dzx3bv0hqkuz2n4pq1epeh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import annoy\n",
    "from gensim.models import FastText\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d59895",
   "metadata": {
    "cellId": "qd1s68pk6miscqt499ns",
    "execution_id": "c921090c-3a05-43c5-8cb9-e2b422e91836"
   },
   "outputs": [],
   "source": [
    "class TrialsModel:\n",
    "    def preprocess_txt(self, line):\n",
    "        spls = \"\".join(i for i in line.strip() if i not in self.exclude).split()\n",
    "        spls = [self.morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "        spls = [i for i in spls if i not in self.sw and i != \"\"]\n",
    "        return spls    \n",
    "    \n",
    "    def train(self, filename):\n",
    "        print(\"Reading dataset\")\n",
    "        trials = pd.read_pickle(filename) #'studies_with_keywords.pickle'\n",
    "\n",
    "        self.morpher = MorphAnalyzer()\n",
    "        self.sw = set(get_stop_words(\"en\"))\n",
    "        self.exclude = set(string.punctuation)\n",
    "\n",
    "        print(\"Preprocessing brief titles\")\n",
    "        trials['words'] = trials.brief_title.apply(preprocess_txt)\n",
    "\n",
    "        print(\"Updating keywords\")\n",
    "        trials.all_keywords = (trials.all_keywords.values + trials.words.values)\n",
    "        trials.all_keywords = trials.all_keywords.apply(set).apply(list)\n",
    "\n",
    "        self.vec_size = 500\n",
    "\n",
    "        print(\"Creating FT model\")\n",
    "        modelFT = FastText(sentences=trials.all_keywords, vector_size=self.vec_size, min_count=1, window=5)\n",
    "\n",
    "        print(\"Creating index\")\n",
    "        ft_index = annoy.AnnoyIndex(self.vec_size,'angular')\n",
    "\n",
    "        for index, row in trials.iterrows():\n",
    "            n_ft = 0\n",
    "            vector_ft = np.zeros(self.vec_size)\n",
    "            for word in row.all_keywords:\n",
    "                if word in modelFT.wv:\n",
    "                    vector_ft += modelFT.wv[word]\n",
    "                    n_ft += 1\n",
    "            if n_ft > 0:\n",
    "                vector_ft = vector_ft / n_ft\n",
    "                ft_index.add_item(index, vector_ft)\n",
    "\n",
    "        print(\"Building index\")\n",
    "        ft_index.build(10)\n",
    "        \n",
    "        self.modelFT = modelFT\n",
    "        self.ft_index = ft_index\n",
    "        self.trials = trials\n",
    "\n",
    "    def get_trials(self, text):\n",
    "        text = preprocess_txt(text)\n",
    "\n",
    "        n_ft = 0\n",
    "        vector_ft = np.zeros(self.vec_size)\n",
    "\n",
    "        for word in text:\n",
    "            if word in self.modelFT.wv:\n",
    "                vector_ft += self.modelFT.wv[word]\n",
    "                n_ft += 1\n",
    "        if n_ft == 0:\n",
    "            return None  \n",
    "\n",
    "        vector_ft = vector_ft / n_ft\n",
    "        idxs = self.ft_index.get_nns_by_vector(vector_ft, 5)\n",
    "\n",
    "        result = 'I have found some clinical trials that might be related to this:\\n\\n'\n",
    "        for i in idxs:\n",
    "            id = self.trials['nct_id'].iloc[i]\n",
    "            title = self.trials['brief_title'].iloc[i]\n",
    "            result += f'<a href=\"https://clinicaltrials.gov/ct2/show/{id}\">{title}</a>\\n'\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf9de4e",
   "metadata": {
    "cellId": "5thrn98v2tpe84pttm71n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "cadd6e4a-13f4-461b-892a-e66344ef5ec1",
  "notebookPath": "NLP_coursework/clinical_trials.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
