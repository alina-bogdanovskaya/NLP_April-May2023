{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e01088e4",
   "metadata": {
    "cellId": "4665f7azx980wjsivxopykb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import numpy as np\n",
    "\n",
    "BASEDIR = 'NLP_coursework'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b2e6c618",
   "metadata": {
    "cellId": "g3jmxu3v9sew0eylqaxdg"
   },
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, prompt_vectorizer, symptoms_discerner, trials_discerner,\n",
    "                 symptoms_model, trials_model, talk_model):\n",
    "        \"\"\"\n",
    "        Construct a chatbot with pre-trained models.\n",
    "\n",
    "        :param prompt_vectorizer: a vectorizer that should be able to handle any prompt string reasonably well\n",
    "        :param symptoms_discerner: a model that can predict if the prompt is a description of symptoms\n",
    "        :param trials_discerner: a model that can predict if the prompt is a request for a clinical trial        \n",
    "        :param symptoms_model: a model that returns a disease by symptoms. It's predict() method should return a string\n",
    "        :param trials_model: a model that returns several relevant clinical trials from a database. Should return a formatted output string\n",
    "        :param talk_model: a model that tries to hold a conversation.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.prompt_vectorizer = prompt_vectorizer\n",
    "        self.symptoms_discerner = symptoms_discerner\n",
    "        self.trials_discerner = trials_discerner\n",
    "        self.symptoms_model = symptoms_model\n",
    "        self.trials_model = trials_model\n",
    "        self.talk_model = talk_model\n",
    "        \n",
    "        self.morpher = MorphAnalyzer()\n",
    "        self.sw = set(get_stop_words(\"en\"))\n",
    "        self.exclude = set(string.punctuation)\n",
    "        \n",
    "        \n",
    "    def preprocess_txt(self, text):\n",
    "        spls = \"\".join(i for i in text.strip() if i not in self.exclude).split()\n",
    "        spls = [self.morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "        spls = [i for i in spls if i not in self.sw and i != \"\"]        \n",
    "        return spls\n",
    "    \n",
    "    def classify_prompt(self, prompt):\n",
    "        input_txt = self.preprocess_txt(prompt)\n",
    "        vect = self.prompt_vectorizer.transform([\" \".join(input_txt)])\n",
    "        if self.symptoms_discerner.predict(vect)[0] == 1:\n",
    "            return \"symptoms\"\n",
    "    \n",
    "        vect = self.prompt_vectorizer.transform([\" \".join(input_txt)])\n",
    "        if self.trials_discerner.predict(vect)[0] == 1:\n",
    "            return \"trials\"\n",
    "    \n",
    "        return \"talk\"\n",
    "    \n",
    "    def process_symptoms(self, prompt):\n",
    "        label = self.symptoms_model.predict(prompt)\n",
    "        return f\"I think you might have {label}, please consult a real doctor.\"\n",
    "    \n",
    "    def process_trials(self, prompt):\n",
    "        return self.trials_model.get_trials(prompt)\n",
    "\n",
    "    def process_talk(self, prompt):\n",
    "        return self.talk_model.predict(prompt)\n",
    "    \n",
    "    def process_message(self, message):\n",
    "        print(f\"Got message: {message}\")\n",
    "        cls = self.classify_prompt(message)\n",
    "        if cls == \"symptoms\":\n",
    "            response = self.process_symptoms(message)\n",
    "        elif cls == \"trials\":\n",
    "            response = self.process_trials(message)            \n",
    "        else:\n",
    "            response = self.process_talk(message)\n",
    "\n",
    "        print(f\"Response: {response}\")\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a234d259",
   "metadata": {
    "cellId": "bb8h1hfcsb53zx6es3jp7d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "class TalkModel:\n",
    "    def __init__(self):\n",
    "        # Загружаем сохранённую модель\n",
    "        # Предобученную модель можно скачать по ссылке https://drive.google.com/drive/folders/1JBp4T9ZLVDkdC19GbY574S6oFPL9665u?usp=sharing \n",
    "        # или обучить заново при помощи ноутбука: text gen for bot.ipynb\n",
    "        training_model = tf.keras.models.load_model(f'{BASEDIR}/chatbot_model', custom_objects={'loss':loss})\n",
    "        \n",
    "        # Подменяем ей входной слой, чтобы батч был из 1 примера\n",
    "        model_config = training_model.get_config()\n",
    "        model_config['layers'][0] = {\n",
    "                      'name': 'new_input',\n",
    "                      'class_name': 'InputLayer',\n",
    "                      'config': {\n",
    "                          'batch_input_shape': (1, None),\n",
    "                          'dtype': 'float32',\n",
    "                          'sparse': False,\n",
    "                          \"ragged\": False,\n",
    "                          'name': 'modified_input'\n",
    "                      },\n",
    "                      'inbound_nodes': []\n",
    "                  }\n",
    "        model_config['layers'][1]['inbound_nodes'] = [[['new_input', 0, 0, {}]]]\n",
    "\n",
    "        # Создаём рабочую модель из изменённой конфигурации и копируем веса\n",
    "        self.model = training_model.__class__.from_config(model_config, custom_objects={'loss':loss})  # change custom objects if necessary\n",
    "        self.model.set_weights(training_model.get_weights())        \n",
    "        \n",
    "        # Загружаем преобразование предсказаний (чисел) в символы и обратно\n",
    "        self.stoi = {}\n",
    "        self.itos = []\n",
    "        with open(f'{BASEDIR}/chatbot_vocab.txt', 'r') as f:\n",
    "            for i, ch in enumerate(f):\n",
    "                self.stoi[ch[0]] = i\n",
    "                self.itos.append(ch[0])        \n",
    "    \n",
    "    def convert_text(self, text):            \n",
    "        dix = [self.stoi[s] for s in text]\n",
    "\n",
    "        return tf.convert_to_tensor(dix, dtype=tf.int32)\n",
    "    \n",
    "    def predict(self, message):\n",
    "        input_eval = self.convert_text(message)\n",
    "        input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "        # Empty string to store our results\n",
    "        text_generated = []\n",
    "\n",
    "        # Low temperature results in more predictable text.\n",
    "        # Higher temperature results in more surprising text.\n",
    "        # Experiment to find the best setting.\n",
    "        temperature = 0.5\n",
    "\n",
    "        self.model.reset_states()\n",
    "        last_char = ''\n",
    "        while last_char not in ['!', '.', '?']:\n",
    "            predictions = self.model(input_eval)\n",
    "            predictions = tf.squeeze(predictions, 0)\n",
    "            # using a categorical distribution to predict the character returned by the model\n",
    "            predictions = predictions / temperature\n",
    "            predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "            # Pass the predicted character as the next input to the model\n",
    "            # along with the previous hidden state\n",
    "            input_eval = tf.expand_dims([predicted_id], 0)\n",
    "            last_char = self.itos[predicted_id]\n",
    "            text_generated.append(last_char)\n",
    "            \n",
    "        return ''.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "24950453",
   "metadata": {
    "cellId": "plcs17iy9al0r0xyhw8w1pb"
   },
   "outputs": [],
   "source": [
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"en\"))\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls\n",
    "\n",
    "def create_talkbot_lines():\n",
    "    all_transcripts = []\n",
    "    \n",
    "    for filename in os.listdir(f'{BASEDIR}/House MD'):\n",
    "        all_transcripts.append(pd.read_csv(f'{BASEDIR}/House MD/{filename}', encoding= 'unicode_escape'))\n",
    "    \n",
    "    talkbot_sentences = pd.concat(all_transcripts)    \n",
    "    \n",
    "    talkbot_lines = []\n",
    "    for line in tqdm(talkbot_sentences.line):\n",
    "        if isinstance(line, str):\n",
    "            talkbot_lines.append(preprocess_txt(line))\n",
    "        \n",
    "    return talkbot_lines\n",
    "\n",
    "def create_symptom_lines():\n",
    "    df_symptoms = pd.read_csv(f'{BASEDIR}/Symptom2Disease.csv')\n",
    "\n",
    "    symptom_lines = []\n",
    "    for line in tqdm(df_symptoms.text):    \n",
    "        if isinstance(line, str):\n",
    "            sentences = line.split(\".\")\n",
    "            for s in sentences:\n",
    "                symptom_lines.append(preprocess_txt(s))\n",
    "                \n",
    "    return symptom_lines\n",
    "\n",
    "def create_trials_lines():\n",
    "    df_trials = pd.read_csv(f'{BASEDIR}/studies.csv')\n",
    "    \n",
    "    trials_lines = []\n",
    "    for (index, row) in tqdm(df_trials.iterrows()):    \n",
    "        if isinstance(row.official_title, str) and len(row.official_title) > 0:\n",
    "            line = row.official_title        \n",
    "        else:\n",
    "            line = row.brief_title\n",
    "    \n",
    "        trials_lines.append(preprocess_txt(line))\n",
    "        \n",
    "    return trials_lines\n",
    "\n",
    "def train_lr_model(positive_texts, list_of_negative_texts, vectorizer):    \n",
    "    negative_texts = []\n",
    "    for nt_list in list_of_negative_texts:\n",
    "        for nt in nt_list:\n",
    "            negative_texts.append(nt)    \n",
    "    \n",
    "    negative_texts = [\" \".join(nt) for nt in negative_texts]\n",
    "    positive_texts = [\" \".join(pt) for pt in positive_texts]    \n",
    "    \n",
    "    dataset = negative_texts + positive_texts\n",
    "    labels = np.zeros(len(dataset))\n",
    "    labels[len(negative_texts):] = np.ones(len(positive_texts))    \n",
    "    \n",
    "    dataset = vectorizer.transform(dataset)\n",
    "    \n",
    "    dataset, labels = SMOTE().fit_resample(dataset, labels)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, stratify=labels,\n",
    "                                                    random_state=13)\n",
    "    \n",
    "    lr = LogisticRegression(max_iter=200).fit(X_train, y_train)\n",
    "        \n",
    "    score = accuracy_score(y_true=y_test, y_pred=lr.predict(X_test))\n",
    "    \n",
    "    return (lr, score)\n",
    "\n",
    "def build_vectorizer(list_of_list_of_text):\n",
    "    all_texts = []\n",
    "    for l in list_of_list_of_text:\n",
    "        for t in l:\n",
    "            all_texts.append(\" \".join(t))\n",
    "            \n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 2))    \n",
    "    vectorizer.fit(all_texts)\n",
    "    \n",
    "    return vectorizer\n",
    "\n",
    "def create_chatbot_from_scratch():\n",
    "    print(\"Loading lines for talk\")    \n",
    "    talkbot_lines = create_talkbot_lines()\n",
    "    print(\"Loading lines for symptoms\")\n",
    "    symptom_lines = create_symptom_lines()\n",
    "    print(\"Loading lines for trials\")\n",
    "    trials_lines = create_trials_lines()\n",
    "    \n",
    "    print(\"Training vectorizer\")\n",
    "    vectorizer = build_vectorizer([symptom_lines, trials_lines, talkbot_lines])\n",
    "    \n",
    "    print(\"Training symptoms discerning model\")\n",
    "    symptoms_lr, acc1 = train_lr_model(symptom_lines, [trials_lines, talkbot_lines], vectorizer)\n",
    "    print(f\"Finished, accuracy={acc1}\")\n",
    "    print(\"Training symptoms trials model\")\n",
    "    trials_lr, acc2 = train_lr_model(trials_lines, [symptom_lines, talkbot_lines], vectorizer)\n",
    "    print(f\"Finished, accuracy={acc2}\")\n",
    "\n",
    "    # Сохранить модель целиком и переносимо не получилось, будем тренировать заново\n",
    "    %run NLP_coursework/symptoms_2_diseases.ipynb\n",
    "    symptoms_model = SymptomsModel()\n",
    "    symptoms_model.train(f'{BASEDIR}/Symptom2Disease.csv')\n",
    "    \n",
    "    %run NLP_coursework/clinical_trials.ipynb\n",
    "    trials_model = TrialsModel()\n",
    "    trials_model.train(f'{BASEDIR}/studies_with_keywords.pickle')\n",
    "    \n",
    "    print(\"Creating chatbot\")\n",
    "    chatbot = Chatbot(vectorizer, symptoms_lr, trials_lr, symptoms_model, trials_model, TalkModel())\n",
    "    print(\"Done!\")\n",
    "    return chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fe7f37c9",
   "metadata": {
    "cellId": "rxcjtotn3qy5arp8zx0p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75312/75312 [00:17<00:00, 4374.13it/s]\n",
      "100%|██████████| 1200/1200 [00:00<00:00, 1798.79it/s]\n",
      "27726it [00:11, 2368.27it/s]\n",
      "/home/jupyter/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lines for talk\n",
      "Loading lines for symptoms\n",
      "Loading lines for trials\n",
      "Training vectorizer\n",
      "Training symptoms discerning model\n",
      "Finished, accuracy=0.9635569574184156\n",
      "Training symptoms trials model\n",
      "Finished, accuracy=0.9633165829145729\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 11ms/step - loss: 3.1578 - accuracy: 0.3094 - val_loss: 3.1352 - val_accuracy: 0.5833\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 3.1009 - accuracy: 0.7125 - val_loss: 3.0786 - val_accuracy: 0.7667\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 3.0226 - accuracy: 0.8448 - val_loss: 2.9963 - val_accuracy: 0.7708\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.9112 - accuracy: 0.8531 - val_loss: 2.8821 - val_accuracy: 0.7958\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.7651 - accuracy: 0.9031 - val_loss: 2.7390 - val_accuracy: 0.8333\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.5861 - accuracy: 0.9042 - val_loss: 2.5673 - val_accuracy: 0.8125\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.3844 - accuracy: 0.9104 - val_loss: 2.3798 - val_accuracy: 0.8292\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 2.1727 - accuracy: 0.9260 - val_loss: 2.1878 - val_accuracy: 0.8458\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.9622 - accuracy: 0.9271 - val_loss: 1.9983 - val_accuracy: 0.8542\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.7592 - accuracy: 0.9469 - val_loss: 1.8190 - val_accuracy: 0.8750\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.5722 - accuracy: 0.9552 - val_loss: 1.6553 - val_accuracy: 0.8875\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.4004 - accuracy: 0.9563 - val_loss: 1.5056 - val_accuracy: 0.9042\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.2456 - accuracy: 0.9698 - val_loss: 1.3723 - val_accuracy: 0.9083\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 1.1079 - accuracy: 0.9771 - val_loss: 1.2530 - val_accuracy: 0.9250\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.9865 - accuracy: 0.9760 - val_loss: 1.1491 - val_accuracy: 0.9250\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.8793 - accuracy: 0.9802 - val_loss: 1.0566 - val_accuracy: 0.9375\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.7854 - accuracy: 0.9833 - val_loss: 0.9747 - val_accuracy: 0.9333\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.7031 - accuracy: 0.9854 - val_loss: 0.9032 - val_accuracy: 0.9375\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6304 - accuracy: 0.9854 - val_loss: 0.8389 - val_accuracy: 0.9458\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5669 - accuracy: 0.9865 - val_loss: 0.7820 - val_accuracy: 0.9542\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.9875 - val_loss: 0.7312 - val_accuracy: 0.9542\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.9906 - val_loss: 0.6850 - val_accuracy: 0.9542\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.9906 - val_loss: 0.6446 - val_accuracy: 0.9542\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.9917 - val_loss: 0.6072 - val_accuracy: 0.9583\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3434 - accuracy: 0.9948 - val_loss: 0.5740 - val_accuracy: 0.9500\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3119 - accuracy: 0.9948 - val_loss: 0.5431 - val_accuracy: 0.9542\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2849 - accuracy: 0.9958 - val_loss: 0.5155 - val_accuracy: 0.9583\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2596 - accuracy: 0.9969 - val_loss: 0.4897 - val_accuracy: 0.9583\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2378 - accuracy: 0.9979 - val_loss: 0.4663 - val_accuracy: 0.9583\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2185 - accuracy: 0.9979 - val_loss: 0.4454 - val_accuracy: 0.9583\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2005 - accuracy: 0.9990 - val_loss: 0.4254 - val_accuracy: 0.9583\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1845 - accuracy: 0.9990 - val_loss: 0.4078 - val_accuracy: 0.9625\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1702 - accuracy: 0.9990 - val_loss: 0.3908 - val_accuracy: 0.9667\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1574 - accuracy: 0.9990 - val_loss: 0.3749 - val_accuracy: 0.9667\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1458 - accuracy: 0.9990 - val_loss: 0.3620 - val_accuracy: 0.9667\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1352 - accuracy: 0.9990 - val_loss: 0.3483 - val_accuracy: 0.9667\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1256 - accuracy: 0.9990 - val_loss: 0.3354 - val_accuracy: 0.9667\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9990 - val_loss: 0.3240 - val_accuracy: 0.9667\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1090 - accuracy: 0.9990 - val_loss: 0.3139 - val_accuracy: 0.9667\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.9990 - val_loss: 0.3047 - val_accuracy: 0.9667\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0952 - accuracy: 0.9990 - val_loss: 0.2950 - val_accuracy: 0.9667\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9990 - val_loss: 0.2864 - val_accuracy: 0.9667\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9990 - val_loss: 0.2791 - val_accuracy: 0.9667\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9990 - val_loss: 0.2709 - val_accuracy: 0.9667\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9990 - val_loss: 0.2641 - val_accuracy: 0.9667\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9990 - val_loss: 0.2575 - val_accuracy: 0.9667\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.0657 - accuracy: 0.9990 - val_loss: 0.2517 - val_accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0620 - accuracy: 0.9990 - val_loss: 0.2447 - val_accuracy: 0.9667\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0586 - accuracy: 0.9990 - val_loss: 0.2396 - val_accuracy: 0.9667\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0554 - accuracy: 0.9990 - val_loss: 0.2341 - val_accuracy: 0.9667\n",
      "Reading dataset\n",
      "Preprocessing brief titles\n",
      "Updating keywords\n",
      "Creating FT model\n",
      "Creating index\n",
      "Building index\n",
      "Creating chatbot\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "chatbot = create_chatbot_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c6639d86",
   "metadata": {
    "cellId": "yqn6u97a7kk9ipfxelviri"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-e9c631946ecf>:22: TelegramDeprecationWarning: The argument `clean` of `start_polling` is deprecated. Please use `drop_pending_updates` instead.\n",
      "  updater.start_polling(clean=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got message: Show me some clinical trials about chronic paint\n",
      "Response: I have found some clinical trials that might be related to this:\n",
      "\n",
      "<a href=\"https://clinicaltrials.gov/ct2/show/NCT00195949\">Laparoscopic Versus Open Pyloromyotomy for Infants With Idiopathic Hypertrophic Pyloric Stenosis</a>\n",
      "<a href=\"https://clinicaltrials.gov/ct2/show/NCT00156403\">A Pilot Study of Use of Calcium Channel Blocker to Decrease Inflammation and Pain in Hereditary Pancreatitis</a>\n",
      "<a href=\"https://clinicaltrials.gov/ct2/show/NCT00080223\">Safety Study of Oral Pirfenidone in Patients With Pulmonary Fibrosis/Idiopathic Pulmonary Fibrosis</a>\n",
      "<a href=\"https://clinicaltrials.gov/ct2/show/NCT00144196\">12 Week Efficacy of Tiotropium Versus Placebo in Patients With Mild COPD According to Swedish Guidelines (SPIRIMILD)</a>\n",
      "<a href=\"https://clinicaltrials.gov/ct2/show/NCT00268762\">Argatroban Stroke Treatment - A Pilot Safety Study</a>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from telegram import Update\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
    "from telegram import ParseMode\n",
    "\n",
    "updater = Updater(\"6068772572:AAHzY182akc1aR2h2SYpfW8mS7P3cLYMLag\", use_context=True) # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "def startCommand(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text='Hi. I\\'m a bot trained in all things medical. Let\\'s talk?\\n' + \n",
    "                             'You can ask me to show you some clinical trials from a database (e.g. Show me some clinical trials about chronic pain)\\n' +\n",
    "                             'Or you can describe me some symptoms, and I\\'ll try to guess a disease (e.g. I have a headache)\\n' + \n",
    "                             'Or you can just chat with me (I\\'m trained on House MD script lines!)')\n",
    "    \n",
    "def textMessage(update, context):\n",
    "    response = chatbot.process_message(update.message.text)\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=response, parse_mode=ParseMode.HTML)\n",
    "        \n",
    "start_command_handler = CommandHandler('start', startCommand)\n",
    "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "dispatcher.add_handler(start_command_handler)\n",
    "dispatcher.add_handler(text_message_handler)\n",
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5e54327d",
   "metadata": {
    "cellId": "l3au2yrdfpecuaiqa69xc"
   },
   "outputs": [],
   "source": [
    "#%pip install python-telegram-bot==13.8"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "3813c494-89de-4c23-9ba5-2fb9ec0a5b30",
  "notebookPath": "NLP_coursework/chatbot.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
