{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccuoYcScfRNe",
    "outputId": "ddb22472-085a-4833-cccc-e32cf50ff0a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting stop_words\n",
      "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docopt>=0.6\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: stop_words, docopt\n",
      "  Building wheel for stop_words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for stop_words: filename=stop_words-2018.7.23-py3-none-any.whl size=32910 sha256=8d7e3397b8bcb90367568da72aee52d468f54b70291d39cfd00a608fb01d180d\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/1a/23/f12552a50cb09bcc1694a5ebb6c2cd5f2a0311de2b8c3d9a89\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=d71d72100ac78eb31459eeb7d6be117464733b3738387c20c8be29d8fc451c6a\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built stop_words docopt\n",
      "Installing collected packages: stop_words, pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 stop_words-2018.7.23\n"
     ]
    }
   ],
   "source": [
    "# pip install stop_words nltk pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "NZBXuMindqRb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from keras.layers import SimpleRNN, LSTM, GRU, Masking, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy \n",
    "from keras.callbacks import EarlyStopping  \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OT3CqdVnWQz",
    "outputId": "c697f145-c472-4ea4-a629-e7ad1f18f24a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]     C:\\Users\\Alina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_ru is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_rows', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "unDK3_roe4uB"
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_excel('отзывы за лето.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UQ8NAzDUp9Ji"
   },
   "outputs": [],
   "source": [
    "reviews.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WAXnOy0ryX7U"
   },
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "  txt = str(txt)\n",
    "  txt = txt.lower()\n",
    "  txt = re.sub('[0-9]|[-—.,:;_%©«»?*!@#№$^•·\"&()]|[+=]|[[]|[]]|[/]|[..]|[...]|[....]|[d]', ' ', txt)\n",
    "  txt = [morph.parse(word)[0].normal_form for word in txt.split() if word not in stopwords.words('russian')]\n",
    "  # txt = \" \".join(txt)\n",
    "  return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeeiJMT-y5eb",
    "outputId": "d7f85483-fd72-49bb-d0cc-a9aa865c1c0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-9a365ce90dba>:6: FutureWarning: Possible nested set at position 40\n",
      "  txt = re.sub('[0-9]|[-—.,:;_%©«»?*!@#№$^•·\"&()]|[+=]|[[]|[]]|[/]|[..]|[...]|[....]|[d]', ' ', txt)\n"
     ]
    }
   ],
   "source": [
    "reviews['clean_text'] = reviews.Content.apply(preprocess_text)\n",
    "reviews['label'] = reviews.Rating.map({5:0, 4:0, 3:1, 2:1, 1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "yyBb-kQa9mlI",
    "outputId": "269c1a25-1ccb-4dc3-936b-29d67424d01b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[it, just, works]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотят слишком большой доступ к персональным данным в телефоне,приходится пользоваться в ограниченном режиме</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[целое, удобноной, приложение, минус, хотеть, слишком, большой, доступ, персональный, данные, телефон, приходиться, пользоваться, ограниченный, режим]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[отлично]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше никуда. Ранее больше года пользовался нормально.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[стать, зависать, работа, антивирус, далёкий, никуда, ранее, год, пользоваться, нормально]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[очень, удобно, работать, быстро]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Всё удобно норм 👍👍👍</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[всё, удобно, норма, 👍👍👍]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобное приложение.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>[очень, удобный, приложение]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                                                                                                                                Content        Date                                                                                                                                              clean_text  label\n",
       "0       5                                                                                                                                         It just works!  2017-08-14                                                                                                                                       [it, just, works]      0\n",
       "1       4  В целом удобноное приложение...из минусов хотят слишком большой доступ к персональным данным в телефоне,приходится пользоваться в ограниченном режиме  2017-08-14  [целое, удобноной, приложение, минус, хотеть, слишком, большой, доступ, персональный, данные, телефон, приходиться, пользоваться, ограниченный, режим]      0\n",
       "2       5                                                                                                                                            Отлично все  2017-08-14                                                                                                                                               [отлично]      0\n",
       "3       5                                                         Стал зависать на 1% работы антивируса. Дальше никуда. Ранее больше года пользовался нормально.  2017-08-14                                                              [стать, зависать, работа, антивирус, далёкий, никуда, ранее, год, пользоваться, нормально]      0\n",
       "4       5                                                                                                                         Очень удобно, работает быстро.  2017-08-14                                                                                                                       [очень, удобно, работать, быстро]      0\n",
       "5       5                                                                                                                                    Всё удобно норм 👍👍👍  2017-08-14                                                                                                                               [всё, удобно, норма, 👍👍👍]      0\n",
       "6       5                                                                                                                              Очень удобное приложение.  2017-08-14                                                                                                                            [очень, удобный, приложение]      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "foTeWNLU4yXN"
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = model_selection.train_test_split(reviews, random_state=678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBsmPqHUJXsY",
    "outputId": "caf41bdf-7795-4777-ef8b-7daa2b56e845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87434\n"
     ]
    }
   ],
   "source": [
    "full_corpus = []\n",
    "\n",
    "for text in train_df.clean_text:\n",
    "  for word in text:\n",
    "    full_corpus.append(word)\n",
    "\n",
    "print(len(full_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDou3RgvMCmB",
    "outputId": "71709c22-c931-4ba0-a845-f983799ac938"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7354"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(full_corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "len(freq_dict_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grkjL1EQMRZO",
    "outputId": "40240d26-a1e7-4bdb-f2d1-2ddd9839b6d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 877, 6340)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_freq_words = []\n",
    "mid_freq_words = []\n",
    "low_freq_words = []\n",
    "\n",
    "for word, freq in freq_dict_sorted:\n",
    "  if freq >= 100:\n",
    "    high_freq_words.append(word)\n",
    "  elif freq < 100 and freq >= 10:\n",
    "    mid_freq_words.append(word)\n",
    "  else: \n",
    "    low_freq_words.append(word)\n",
    "\n",
    "len(high_freq_words), len(mid_freq_words), len(low_freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHzMyKZqbvpL",
    "outputId": "0c53c30f-8508-4153-a5a3-d8a8204404fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1014"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = high_freq_words + mid_freq_words\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "naglIxcOoNOA",
    "outputId": "6e94a8a2-0091-4067-b1e3-01a665d84059"
   },
   "outputs": [],
   "source": [
    "vec1 = CountVectorizer(lowercase=False, analyzer=lambda x: x, ngram_range=(1, 4), vocabulary=vocab)\n",
    "x_train_cv = vec1.fit_transform(train_df.clean_text).toarray()\n",
    "x_valid_cv = vec1.fit_transform(valid_df.clean_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Dq-0Ak7SPnAD"
   },
   "outputs": [],
   "source": [
    "vec2 = TfidfVectorizer(lowercase=False, analyzer=lambda x: x, ngram_range=(1, 4), vocabulary=vocab)\n",
    "x_train_tfidf = vec2.fit_transform(train_df.clean_text).toarray()\n",
    "x_valid_tfidf = vec2.fit_transform(valid_df.clean_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qfEKg3Ek_o5I"
   },
   "outputs": [],
   "source": [
    "max_words = len(freq_dict_sorted)\n",
    "max_len = len(vocab)\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jIdicJsA7rI",
    "outputId": "ae2b05eb-ba0c-4e0a-c328-b3da4c0c0eb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15492, 1014), (15492, 1014))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cv.shape, x_train_tfidf.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6OmyRYPVfik",
    "outputId": "cdac945c-c4db-4c28-dec4-828d2f7e5d59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5164, 1014), (5164, 1014))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid_cv.shape, x_valid_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "i1WghmzqBcPs"
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(train_df.label, num_classes)\n",
    "y_valid = keras.utils.to_categorical(valid_df.label, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2ZCcC2r9FqPe"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DwTrVXLnFzgT"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='CategoricalCrossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XngCit1MF5zf",
    "outputId": "af30c5fe-afd2-4d14-8bdd-e0c43e87c104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "109/109 [==============================] - 22s 117ms/step - loss: 0.4635 - accuracy: 0.8183 - val_loss: 0.4358 - val_accuracy: 0.8310\n",
      "Epoch 2/20\n",
      "109/109 [==============================] - 12s 112ms/step - loss: 0.4363 - accuracy: 0.8281 - val_loss: 0.4381 - val_accuracy: 0.8323\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "history = model.fit(x_train_cv, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPtqblXPGFjg",
    "outputId": "80227edb-95da-473d-fbc6-6750ad39ad84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 48ms/step - loss: 0.4547 - accuracy: 0.8292\n",
      "\n",
      "\n",
      "Test score: 0.45471957325935364\n",
      "Test accuracy: 0.8292021751403809\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_valid_cv, y_valid, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Jv46nwjYYutB"
   },
   "outputs": [],
   "source": [
    "y_train_rnn = train_df.label.values\n",
    "y_valid_rnn = valid_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "fkjCIBMh6urn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=max_words, output_dim=30, input_length=max_len, trainable=True, mask_zero=True))\n",
    "model_lstm.add(Masking(mask_value=0.0))\n",
    "model_lstm.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(64, activation='relu'))\n",
    "model_lstm.add(Dropout(0.5))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2T-2L3Id7qyh"
   },
   "outputs": [],
   "source": [
    "model_lstm.compile(loss='BinaryCrossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zym3iaQ379Av",
    "outputId": "5b20bdcb-6102-44a2-c7b0-89233cc122ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "109/109 [==============================] - 830s 8s/step - loss: 0.5073 - accuracy: 0.8116 - val_loss: 0.4822 - val_accuracy: 0.8142\n",
      "Epoch 2/20\n",
      "109/109 [==============================] - 789s 7s/step - loss: 0.4911 - accuracy: 0.8127 - val_loss: 0.4820 - val_accuracy: 0.8142\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "history = model_lstm.fit(x_train_cv, y_train_rnn,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QNQFtx8H75dI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 28s 676ms/step - loss: 0.5067 - accuracy: 0.7994\n",
      "\n",
      "\n",
      "Test score: 0.506669819355011\n",
      "Test accuracy: 0.7993803024291992\n"
     ]
    }
   ],
   "source": [
    "score = model_lstm.evaluate(x_valid_cv, y_valid_rnn, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model_gru = Sequential()\n",
    "model_gru.add(Embedding(input_dim=max_words, output_dim=30, input_length=max_len, trainable=True, mask_zero=True))\n",
    "model_gru.add(Masking(mask_value=0.0))\n",
    "model_gru.add(GRU(64, recurrent_dropout=0.2))\n",
    "model_gru.add(Dense(64, activation='relu'))\n",
    "model_gru.add(Dropout(0.5))\n",
    "model_gru.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru.compile(loss='BinaryCrossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "109/109 [==============================] - 730s 7s/step - loss: 0.5113 - accuracy: 0.8120 - val_loss: 0.4800 - val_accuracy: 0.8142\n",
      "Epoch 2/20\n",
      "109/109 [==============================] - 715s 7s/step - loss: 0.4904 - accuracy: 0.8127 - val_loss: 0.4816 - val_accuracy: 0.8142\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "history = model_gru.fit(x_train_cv, y_train_rnn,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 26s 633ms/step - loss: 0.5014 - accuracy: 0.7994\n",
      "\n",
      "\n",
      "Test score: 0.5014299750328064\n",
      "Test accuracy: 0.7993803024291992\n"
     ]
    }
   ],
   "source": [
    "score = model_gru.evaluate(x_valid_cv, y_valid_rnn, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comb = Sequential()\n",
    "model_comb.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model_comb.add(Conv1D(128, 3))\n",
    "model_comb.add(Activation(\"relu\"))\n",
    "model_comb.add(MaxPooling1D(pool_size=2))\n",
    "model_comb.add(LSTM(100))\n",
    "# model_comb.add(Dropout(0.2))\n",
    "model_comb.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comb.compile(loss='BinaryCrossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "109/109 [==============================] - 25s 206ms/step - loss: 0.4935 - accuracy: 0.8063 - val_loss: 0.4818 - val_accuracy: 0.8142\n",
      "Epoch 2/20\n",
      "109/109 [==============================] - 22s 201ms/step - loss: 0.4823 - accuracy: 0.8127 - val_loss: 0.4760 - val_accuracy: 0.8155\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "history = model_comb.fit(x_train_cv, y_train_rnn,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 3s 80ms/step - loss: 0.4985 - accuracy: 0.7978\n",
      "\n",
      "\n",
      "Test score: 0.4984525740146637\n",
      "Test accuracy: 0.797831118106842\n"
     ]
    }
   ],
   "source": [
    "score = model_comb.evaluate(x_valid_cv, y_valid_rnn, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comb2 = Sequential()\n",
    "model_comb2.add(Embedding(input_dim=max_words, output_dim=30, input_length=max_len, trainable=True, mask_zero=True))\n",
    "model_comb2.add(LSTM(128, return_sequences=True))\n",
    "model_comb2.add(Conv1D(128, 3))\n",
    "model_comb2.add(Activation(\"relu\"))\n",
    "model_comb2.add(MaxPooling1D(pool_size=2))\n",
    "model_comb2.add(Conv1D(64, 3))\n",
    "model_comb2.add(Activation(\"relu\"))\n",
    "model_comb2.add(GlobalMaxPool1D())\n",
    "# model_comb.add(Dropout(0.2))\n",
    "model_comb2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comb2.compile(loss='BinaryCrossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "109/109 [==============================] - 455s 4s/step - loss: 0.4324 - accuracy: 0.8261 - val_loss: 0.3857 - val_accuracy: 0.8381\n",
      "Epoch 2/20\n",
      "109/109 [==============================] - 454s 4s/step - loss: 0.3631 - accuracy: 0.8411 - val_loss: 0.3774 - val_accuracy: 0.8400\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "history = model_comb2.fit(x_train_cv, y_train_rnn,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 21s 515ms/step - loss: 0.3694 - accuracy: 0.8490\n",
      "\n",
      "\n",
      "Test score: 0.36941367387771606\n",
      "Test accuracy: 0.8489543199539185\n"
     ]
    }
   ],
   "source": [
    "score = model_comb2.evaluate(x_valid_cv, y_valid_rnn, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comb3 = Sequential()\n",
    "model_comb3.add(Embedding(input_dim=max_words, output_dim=30, input_length=max_len, trainable=True, mask_zero=True))\n",
    "model_comb3.add(LSTM(128, return_sequences=True))\n",
    "model_comb3.add(Conv1D(128, 3))\n",
    "model_comb3.add(Activation(\"relu\"))\n",
    "model_comb3.add(GlobalMaxPool1D())\n",
    "# model_comb.add(Dropout(0.2))\n",
    "model_comb3.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comb3.compile(loss='BinaryCrossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "109/109 [==============================] - 447s 4s/step - loss: 0.4460 - accuracy: 0.8282 - val_loss: 0.4094 - val_accuracy: 0.8290\n",
      "Epoch 2/20\n",
      "109/109 [==============================] - 439s 4s/step - loss: 0.3867 - accuracy: 0.8389 - val_loss: 0.3957 - val_accuracy: 0.8348\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "history = model_comb3.fit(x_train_cv, y_train_rnn,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 20s 482ms/step - loss: 0.3841 - accuracy: 0.8373\n",
      "\n",
      "\n",
      "Test score: 0.38406020402908325\n",
      "Test accuracy: 0.8373354077339172\n"
     ]
    }
   ],
   "source": [
    "score = model_comb3.evaluate(x_valid_cv, y_valid_rnn, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "Рекуррентные сети в целом показали худшие результаты, чем сверточные. Комбинация CNN->LSTM закономерно обучается гораздо быстрее, чем LSTM/GRU сами по себе, но результат показывает схожий. Самый лучший результат показывает комбинация LSTM->CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
